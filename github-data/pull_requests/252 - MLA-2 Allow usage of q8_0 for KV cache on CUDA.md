## ðŸ”€ [Pull Request #252](https://github.com/ikawrakow/ik_llama.cpp/pull/252) - MLA-2: Allow usage of q8_0 for KV cache  on CUDA

| **Author** | `ikawrakow` |
| :--- | :--- |
| **State** | ðŸ”€ **Merged** |
| **Source Branch** | `ik/cuda_flash_mla_q8_0` |
| **Target Branch** | `main` |
| **Created** | 2025-03-12 |
| **Updated** | 2025-03-12 |
| **Merged** | 2025-03-12 |

---

## ðŸ“„ Description

Performance is slightly lower than `f16` KV cache but not too bad.