## ðŸ”€ [Pull Request #330](https://github.com/ikawrakow/ik_llama.cpp/pull/330) - Allow q8_0 KV cache for head size 256

| **Author** | `ikawrakow` |
| :--- | :--- |
| **State** | ðŸ”€ **Merged** |
| **Source Branch** | `ik/gemma_q80_kvcache` |
| **Target Branch** | `main` |
| **Created** | 2025-04-15 |
| **Updated** | 2025-04-15 |
| **Merged** | 2025-04-15 |

---

## ðŸ“„ Description

Gemma models have a head size of 256. For whatever reason, the inherited CUDA FA code only allows `fp16` KV cache for this head size. This PR adds the ability to also use `Q8_0` KV cache with FA.